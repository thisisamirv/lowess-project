#!/usr/bin/env python3
"""
Combined Visualization Script for fastLowess Examples.

This script generates plots for all the CSV data generated by `cargo run --example visual`.
It includes:
1. Degree Comparison
2. Fraction Comparison
3. Intervals Comparison
4. Robustness Comparison
5. fastLowess Concept
6. Multivariate fastLowess

Usage:
    python3 plot.py [target]

    If no target is specified, 'all' plots are generated.
"""

import sys
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np
import os

INPUT_DIR = 'output/visual'
OUTPUT_DIR = 'output/fig'

# Optimized SVG settings
plt.rcParams['svg.fonttype'] = 'none'


def check_file(filename):
    filepath = os.path.join(INPUT_DIR, filename)
    if not os.path.exists(filepath):
        print(f"Error: {filepath} not found. Run 'cargo run --bin visual' first.")
        return False
    return True

def get_input_path(filename):
    return os.path.join(INPUT_DIR, filename)

def get_output_path(filename):
    return os.path.join(OUTPUT_DIR, filename)

def plot_degree_comparison():
    if not check_file('degree_comparison.csv'): return
    print("Plotting Degree Comparison...")
    
    df = pd.read_csv(get_input_path('degree_comparison.csv'))
    fig, axes = plt.subplots(1, 2, figsize=(10, 4))

    # Left: Full comparison
    ax1 = axes[0]
    ax1.plot(df['x'], df['y_noisy'], 'o', markersize=3, alpha=0.4, color='gray', markeredgewidth=0, label='Noisy data', rasterized=True)
    ax1.plot(df['x'], df['y_true'], 'k-', lw=1.5, label='True signal', alpha=0.7)
    ax1.plot(df['x'], df['y_lowess'], 'b-', lw=2, label='LOWESS (Linear)')
    ax1.plot(df['x'], df['y_fastLowess'], 'r-', lw=2, label='fastLowess (Quadratic)')
    ax1.set_xlabel('x', fontsize=12)
    ax1.set_ylabel('y', fontsize=12)
    ax1.set_title('LOWESS vs fastLowess: Full View', fontsize=14)
    ax1.legend(loc='upper right')
    ax1.grid(True, alpha=0.3)

    # Right: Zoomed on peak
    ax2 = axes[1]
    mask = (df['x'] > -0.6) & (df['x'] < 0.6)
    ax2.plot(df.loc[mask, 'x'], df.loc[mask, 'y_noisy'], 'o', markersize=4, alpha=0.5, color='gray', markeredgewidth=0, label='Noisy data', rasterized=True)
    ax2.plot(df.loc[mask, 'x'], df.loc[mask, 'y_true'], 'k-', lw=2, label='True signal')
    ax2.plot(df.loc[mask, 'x'], df.loc[mask, 'y_lowess'], 'b-', lw=2.5, label='LOWESS (Linear)')
    ax2.plot(df.loc[mask, 'x'], df.loc[mask, 'y_fastLowess'], 'r-', lw=2.5, label='fastLowess (Quadratic)')
    ax2.set_xlabel('x', fontsize=12)
    ax2.set_ylabel('y', fontsize=12)
    ax2.set_title('Peak Region: Linear Flattens, Quadratic Captures', fontsize=14)
    ax2.legend(loc='lower center')
    ax2.grid(True, alpha=0.3)

    peak_x = df.loc[df['y_true'].idxmax(), 'x']
    peak_true = df['y_true'].max()
    peak_lowess = df.loc[df['y_true'].idxmax(), 'y_lowess']
    
    ax2.annotate(f'Gap = {peak_true - peak_lowess:.3f}', 
                 xy=(peak_x, (peak_lowess + peak_true)/2), 
                 xytext=(0.3, 0.85), fontsize=10, color='blue',
                 arrowprops=dict(arrowstyle='->', color='blue', lw=1.5))

    plt.tight_layout()
    output_file = get_output_path('degree_comparison.svg')
    plt.savefig(output_file, format='svg', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_fraction_comparison():
    if not check_file('fraction_comparison.csv'): return
    print("Plotting Fraction Comparison...")
    
    df = pd.read_csv(get_input_path('fraction_comparison.csv'))
    fig, axes = plt.subplots(1, 3, figsize=(12, 4))

    fractions = [0.2, 0.5, 0.9]
    colors = ['#e74c3c', '#3498db', '#2ecc71']
    titles = [
        'Small Fraction (0.2)\nCaptures Details, May Overfit',
        'Medium Fraction (0.5)\nBalanced Smoothing',
        'Large Fraction (0.9)\nVery Smooth, May Underfit'
    ]

    for i, (ax, frac, color, title) in enumerate(zip(axes, fractions, colors, titles)):
        ax.plot(df['x'], df['y_noisy'], 'o', markersize=3.5, alpha=0.3, color='gray', markeredgewidth=0, label='Noisy data', zorder=1, rasterized=True)
        ax.plot(df['x'], df['y_true'], 'k--', lw=1.5, label='True signal', alpha=0.6, zorder=2)
        ax.plot(df['x'], df[f'y_frac_{frac}'], color=color, lw=2.5, 
                label=f'fastLowess (fraction={frac})', zorder=3)
        
        ax.set_xlabel('x', fontsize=12)
        ax.set_ylabel('y', fontsize=12)
        ax.set_title(title, fontsize=13, fontweight='bold')
        ax.legend(loc='upper left', fontsize=10)
        ax.grid(True, alpha=0.3)
        
        rmse = ((df[f'y_frac_{frac}'] - df['y_true'])**2).mean()**0.5
        ax.text(0.98, 0.02, f'RMSE: {rmse:.3f}', 
                transform=ax.transAxes, fontsize=11,
                ha='right', va='bottom',
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

    fig.suptitle('Effect of Fraction Parameter on fastLowess Smoothing', 
                 fontsize=16, fontweight='bold', y=1.02)
    plt.tight_layout()
    output_file = get_output_path('fraction_comparison.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_intervals_comparison():
    if not check_file('intervals_comparison.csv'): return
    print("Plotting Intervals Comparison...")
    
    df = pd.read_csv(get_input_path('intervals_comparison.csv'))
    fig, ax = plt.subplots(figsize=(10, 8))

    ax.plot(df['x'], df['y_noisy'], 'o', markersize=4.5, alpha=0.6, color='gray', markeredgewidth=0, label='Noisy Data', zorder=1)
    ax.plot(df['x'], df['y_true'], 'k--', lw=1.5, label='True Signal', alpha=0.7, zorder=2)
    ax.plot(df['x'], df['y_smooth'], 'k-', lw=2.5, label='fastLowess Fit', zorder=5)

    # Prediction Intervals
    ax.fill_between(df['x'], df['pred_lower'], df['pred_upper'], 
                    alpha=0.2, color='#3b82f6', label='95% Prediction Interval', zorder=3)
    ax.plot(df['x'], df['pred_lower'], linestyle='--', color='#1d4ed8', lw=1.5, alpha=0.6)
    ax.plot(df['x'], df['pred_upper'], linestyle='--', color='#1d4ed8', lw=1.5, alpha=0.6)

    # Confidence Intervals
    ax.fill_between(df['x'], df['conf_lower'], df['conf_upper'], 
                    alpha=0.4, color='#22c55e', label='95% Confidence Interval', zorder=4)
    ax.plot(df['x'], df['conf_lower'], linestyle='--', color='#15803d', lw=1.5, alpha=0.8)
    ax.plot(df['x'], df['conf_upper'], linestyle='--', color='#15803d', lw=1.5, alpha=0.8)

    ax.set_xlabel('x', fontsize=12)
    ax.set_ylabel('y', fontsize=12)
    ax.set_title('Uncertainty Decomposition: Confidence vs Prediction Intervals', fontsize=14, fontweight='bold')
    ax.legend(loc='upper left', fontsize=10, framealpha=0.9)
    ax.grid(True, alpha=0.3)

    avg_pred_width = (df['pred_upper'] - df['pred_lower']).mean()
    avg_conf_width = (df['conf_upper'] - df['conf_lower']).mean()
    
    footnote_text = (
        f"Avg Width Ratio (Pred/Conf): {avg_pred_width/avg_conf_width:.2f}x\n"
        "Confidence Interval: Uncertainty in mean curve (Green)\n"
        "Prediction Interval: Uncertainty for new observations (Blue)"
    )
    plt.subplots_adjust(bottom=0.15)
    fig.text(0.05, 0.02, footnote_text, fontsize=11, family='monospace', va='bottom', ha='left')
    
    output_file = get_output_path('intervals_comparison.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_robustness_comparison():
    if not check_file('robustness_comparison.csv'): return
    print("Plotting Robustness Comparison...")
    
    df = pd.read_csv(get_input_path('robustness_comparison.csv'))
    fig, ax = plt.subplots(figsize=(12, 7))

    ax.plot(df['x'], df['y_noisy'], 'o', markersize=5.5, alpha=0.6, color='gray', markeredgewidth=0, label='Noisy Data', zorder=1)
    ax.plot(df['x'], df['y_true'], 'k--', lw=1.5, label='True Signal', alpha=0.6, zorder=2)
    ax.plot(df['x'], df['y_non_robust'], color='#ef4444', lw=2.0, alpha=0.9, label='Non-Robust (0 iter)')
    ax.plot(df['x'], df['y_robust'], color='#10b981', lw=3.0, alpha=0.95, label='Robust (6 iter)')

    outlier_mask = np.abs(df['y_noisy'] - df['y_true']) > 2.0
    ax.scatter(df.loc[outlier_mask, 'x'], df.loc[outlier_mask, 'y_noisy'], 
               s=80, facecolors='none', edgecolors='#ef4444', lw=1.5, label='Outliers', zorder=5)

    ax.set_xlabel('x', fontsize=12)
    ax.set_ylabel('y', fontsize=12)
    ax.set_ylim(-10, 25)
    ax.set_title('Impact of Robustness Iterations', fontsize=14, fontweight='bold')
    ax.legend(loc='lower left', fontsize=10)
    ax.grid(True, alpha=0.3)
    
    output_file = get_output_path('robustness_comparison.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_fastLowess_concept():
    if not check_file('fastLowess_concept.csv'): return
    print("Plotting fastLowess Concept...")
    
    df = pd.read_csv(get_input_path('fastLowess_concept.csv'))
    focus_row = df[df['is_focus'] == 1].iloc[0]
    x0 = focus_row['x']
    y0_fit = focus_row['y_smooth']
    neighborhood = df[df['weight'] > 0]

    fig, ax = plt.subplots(figsize=(12, 7))

    ax.scatter(df['x'], df['y_noisy'], c='lightgray', s=30, alpha=0.5, label='Other Data')
    ax.plot(df['x'], df['y_smooth'], color='black', lw=2, alpha=0.3, label='Global Curve')

    sc = ax.scatter(neighborhood['x'], neighborhood['y_noisy'], 
                    c=neighborhood['weight'], cmap='Blues', s=60, 
                    edgecolor='k', linewidth=0.5, label='Neighborhood')

    ax.plot(neighborhood['x'], neighborhood['y_local_fit_x0'], 
            color='#d97706', lw=3, label='Local Polynomial')

    ax.scatter([x0], [y0_fit], s=150, facecolor='#d97706', edgecolor='white', lw=2, zorder=10, 
               label='Fitted Value')

    ax.set_title(f'How fastLowess Works (Focus x={x0:.2f})', fontsize=14, fontweight='bold')
    ax.legend(loc='upper right')
    ax.grid(True, alpha=0.3)
    
    cbar = fig.colorbar(sc, ax=ax)
    cbar.set_label('Weight', fontsize=10)
    
    output_file = get_output_path('fastLowess_concept.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_multivariate_fastLowess():
    if not check_file('multivariate_fastLowess.csv'): return
    print("Plotting Multivariate fastLowess...")
    
    df = pd.read_csv(get_input_path('multivariate_fastLowess.csv'))
    n_x = len(df['x'].unique())
    n_y = len(df['y'].unique())
    X = df['x'].values.reshape(n_x, n_y)
    Y = df['y'].values.reshape(n_x, n_y)
    Z_true = df['z_true'].values.reshape(n_x, n_y)
    Z_smooth = df['z_smooth'].values.reshape(n_x, n_y)
    
    fig = plt.figure(figsize=(10, 5))

    # 1. True surface
    ax1 = fig.add_subplot(1, 2, 1, projection='3d')
    surf1 = ax1.plot_surface(X, Y, Z_true, cmap='viridis', alpha=0.9, edgecolor='none', rasterized=True)
    ax1.set_title('True Surface')
    ax1.locator_params(nbins=4)
    cb1 = fig.colorbar(surf1, ax=ax1, shrink=0.5)
    cb1.solids.set_rasterized(True)

    # 2. fastLowess smoothed surface
    ax2 = fig.add_subplot(1, 2, 2, projection='3d')
    surf2 = ax2.plot_surface(X, Y, Z_smooth, cmap='magma', alpha=0.9, edgecolor='none', rasterized=True)
    ax2.set_title('fastLowess Smoothed')
    ax2.locator_params(nbins=4)
    cb2 = fig.colorbar(surf2, ax=ax2, shrink=0.5)
    cb2.solids.set_rasterized(True)

    plt.tight_layout()
    output_file = get_output_path('multivariate_fastLowess.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=100)
    print(f'Saved to {output_file}')
    plt.close()

def plot_kernel_comparison():
    if not check_file('kernel_comparison.csv'): return
    print("Plotting Kernel Comparison...")
    
    df = pd.read_csv(get_input_path('kernel_comparison.csv'))
    fig, ax = plt.subplots(figsize=(10, 6))

    ax.plot(df['x'], df['y_noisy'], 'o', markersize=3, alpha=0.3, color='gray', label='Noisy Data')
    ax.plot(df['x'], df['y_true'], 'k--', lw=1.5, label='True Signal', alpha=0.5)
    
    configs = [
        ('y_tricube', 'Tricube', '-', '#3b82f6', 3.0),
        ('y_gaussian', 'Gaussian', '--', '#ef4444', 2.0),
        ('y_uniform', 'Uniform', ':', '#10b981', 2.0),
        ('y_cosine', 'Cosine', '-', '#f59e0b', 2.0),
        ('y_epanechnikov', 'Epanechnikov', '--', '#8b5cf6', 2.0),
        ('y_biweight', 'Biweight', ':', '#06b6d4', 2.0),
        ('y_triangle', 'Triangle', '-', '#ec4899', 2.0),
    ]

    for col, name, style, color, lw in configs:
        if col in df.columns:
            ax.plot(df['x'], df[col], linestyle=style, lw=lw, label=name, color=color)

    ax.set_title('Impact of Different Kernel (Weight) Functions', fontsize=14, fontweight='bold')
    ax.set_xlabel('x')
    ax.set_ylabel('y')
    ax.legend(loc='upper right', framealpha=0.9, fontsize=9)
    ax.grid(True, alpha=0.3)

    output_file = get_output_path('kernel_comparison.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_robust_method_comparison():
    if not check_file('robust_method_comparison.csv'): return
    print("Plotting Robust Method Comparison...")
    
    df = pd.read_csv(get_input_path('robust_method_comparison.csv'))
    fig, ax = plt.subplots(figsize=(12, 7))

    ax.plot(df['x'], df['y_noisy'], 'o', markersize=4, alpha=0.4, color='gray', label='Data with Outliers')
    ax.plot(df['x'], df['y_true'], 'k--', lw=1, label='True Signal', alpha=0.5)
    
    ax.plot(df['x'], df['y_bisquare'], '-', lw=2.5, label='Bisquare (Aggressive)', color='#3b82f6')
    ax.plot(df['x'], df['y_huber'], '--', lw=2, label='Huber (Balanced)', color='#ef4444')
    ax.plot(df['x'], df['y_talwar'], ':', lw=2, label='Talwar (Hard Cutoff)', color='#10b981')

    ax.set_title('Outlier Resistance by Robustness Method', fontsize=14, fontweight='bold')
    ax.set_xlabel('x')
    ax.set_ylabel('y')
    ax.legend()
    ax.grid(True, alpha=0.3)

    output_file = get_output_path('robust_method_comparison.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_boundary_policy_comparison():
    if not check_file('boundary_comparison.csv'): return
    print("Plotting Boundary Policy Comparison...")
    
    df = pd.read_csv(get_input_path('boundary_comparison.csv'))
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

    for ax in [ax1, ax2]:
        ax.plot(df['x'], df['y_noisy'], 'o', markersize=3, alpha=0.3, color='gray', label='Noisy Data')
        ax.plot(df['x'], df['y_true'], 'k--', lw=1, label='True Signal', alpha=0.5)
        ax.plot(df['x'], df['y_none'], '-', lw=2, label='NoBoundary', color='#ef4444')
        ax.plot(df['x'], df['y_extend'], '--', lw=2, label='Extend', color='#3b82f6')
        ax.plot(df['x'], df['y_reflect'], '-.', lw=2, label='Reflect', color='#10b981')
        ax.grid(True, alpha=0.3)

    # Zoomed views
    ax1.set_xlim(-0.05, 0.2)
    ax1.set_ylim(0.8, 2.0)
    ax1.set_title('Left Boundary Impact')
    
    ax2.set_xlim(0.8, 1.05)
    ax2.set_ylim(10, 22)
    ax2.set_title('Right Boundary Impact')

    fig.suptitle('Mitigating Boundary Bias with Reflection and Extension', fontsize=16, fontweight='bold')
    ax2.legend(loc='lower right')

    output_file = get_output_path('boundary_comparison.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_higher_degree_comparison():
    if not check_file('higher_degree_comparison.csv'): return
    print("Plotting Higher Degree Comparison...")
    
    df = pd.read_csv(get_input_path('higher_degree_comparison.csv'))
    fig, ax = plt.subplots(figsize=(10, 6))

    ax.plot(df['x'], df['y_noisy'], 'o', markersize=3, alpha=0.3, color='gray', label='Noisy Data')
    ax.plot(df['x'], df['y_true'], 'k--', lw=1, label='True Signal', alpha=0.5)
    
    ax.plot(df['x'], df['y_quadratic'], '-', lw=2, label='Quadratic (Degree 2)', color='#ef4444')
    ax.plot(df['x'], df['y_cubic'], '--', lw=2.5, label='Cubic (Degree 3)', color='#3b82f6')
    ax.plot(df['x'], df['y_quartic'], ':', lw=2.5, label='Quartic (Degree 4)', color='#10b981')

    ax.set_title('Handling Complex Curvature with Higher Degrees', fontsize=14, fontweight='bold')
    ax.set_xlabel('x')
    ax.set_ylabel('y')
    ax.legend()
    ax.grid(True, alpha=0.3)

    output_file = get_output_path('higher_degree_comparison.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_gap_handling():
    if not check_file('gap_handling.csv'): return
    print("Plotting Gap Handling...")
    
    df = pd.read_csv(get_input_path('gap_handling.csv'))
    fig, ax = plt.subplots(figsize=(10, 6))

    ax.plot(df['x'], df['y_noisy'], 'o', markersize=4, alpha=0.6, color='#3b82f6', label='Available Data')
    ax.plot(df['x'], df['y_smooth'], 'r-', lw=3, label='fastLowess Interpolation')

    ax.set_title('fastLowess Gap Handling (Bridging Missing Regions)', fontsize=14, fontweight='bold')
    ax.set_xlabel('x')
    ax.set_ylabel('y')
    ax.axvspan(4.0, 7.0, color='gray', alpha=0.1, label='Missing Data Region')
    ax.legend()
    ax.grid(True, alpha=0.3)
    output_file = get_output_path('gap_handling.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_cv_comparison():
    if not check_file('cv_scores.csv') or not check_file('cv_fits.csv'): return
    print("Plotting Cross-Validation Comparison...")
    
    df_scores = pd.read_csv(get_input_path('cv_scores.csv'))
    df_fits = pd.read_csv(get_input_path('cv_fits.csv'))
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # 1. Scores Plot
    ax1.plot(df_scores['fraction'], df_scores['loocv_rmse'], 'o-', label='LOOCV RMSE', color='#3b82f6')
    ax1.plot(df_scores['fraction'], df_scores['kfold_rmse'], 's--', label='5-Fold RMSE', color='#ef4444')
    
    # Annotate best fractions
    best_loocv_f = df_scores.loc[df_scores['loocv_rmse'].idxmin(), 'fraction']
    best_kfold_f = df_scores.loc[df_scores['kfold_rmse'].idxmin(), 'fraction']
    
    ax1.axvline(best_loocv_f, color='#3b82f6', alpha=0.3, linestyle='-')
    ax1.axvline(best_kfold_f, color='#ef4444', alpha=0.3, linestyle='--')
    
    ax1.set_title('Bandwidth Selection: CV Score vs Fraction', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Smoothing Fraction')
    ax1.set_ylabel('RMSE')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # 2. Fits Plot
    ax2.plot(df_fits['x'], df_fits['y_noisy'], 'o', markersize=3, alpha=0.3, color='gray', label='Noisy Data')
    ax2.plot(df_fits['x'], df_fits['y_true'], 'k--', lw=1.5, label='True Signal', alpha=0.5)
    
    ax2.plot(df_fits['x'], df_fits['y_loocv'], '-', lw=2.5, label=f'LOOCV (f={best_loocv_f})', color='#3b82f6')
    ax2.plot(df_fits['x'], df_fits['y_kfold'], '--', lw=2, label=f'5-Fold (f={best_kfold_f})', color='#ef4444')
    ax2.plot(df_fits['x'], df_fits['y_fixed'], ':', lw=2, label='No CV (f=0.1, Overfit)', color='#10b981')

    ax2.set_title('Impact of Bandwidth Selection on Fit', fontsize=14, fontweight='bold')
    ax2.set_xlabel('x')
    ax2.set_ylabel('y')
    ax2.legend(loc='upper right', fontsize=9)
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    output_file = get_output_path('cv_comparison.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_surface_mode_comparison():
    if not check_file('surface_mode_comparison.csv'): return
    print("Plotting Surface Mode Comparison...")
    df = pd.read_csv(get_input_path('surface_mode_comparison.csv'))
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(df['x'], df['y_noisy'], 'o', markersize=3, alpha=0.3, color='gray', label='Noisy Data')
    ax.plot(df['x'], df['y_true'], 'k--', lw=1, label='True Signal', alpha=0.5)
    ax.plot(df['x'], df['y_direct'], '-', lw=2.5, label='Direct Mode', color='#3b82f6')
    ax.plot(df['x'], df['y_interpolation'], '--', lw=2, label='Interpolation Mode', color='#ef4444')
    ax.set_title('Direct vs Interpolation Evaluation', fontsize=14, fontweight='bold')
    ax.legend()
    ax.grid(True, alpha=0.3)
    output_file = get_output_path('surface_comparison.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_scaling_comparison():
    if not check_file('scaling_comparison.csv'): return
    print("Plotting Scaling Method Comparison...")
    df = pd.read_csv(get_input_path('scaling_comparison.csv'))
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(df['x'], df['y_noisy'], 'o', markersize=4, alpha=0.4, color='gray', label='Data with Outliers')
    ax.plot(df['x'], df['y_true'], 'k--', lw=1, label='True Signal', alpha=0.5)
    ax.plot(df['x'], df['y_mad'], '-', lw=2.5, label='MAD Scaling (Median Abs Dev)', color='#3b82f6')
    ax.plot(df['x'], df['y_mar'], '--', lw=2.5, label='MAR Scaling (Median Abs Residual)', color='#ef4444')
    ax.set_title('Robust Residual Scaling: MAD vs MAR', fontsize=14, fontweight='bold')
    ax.legend()
    ax.grid(True, alpha=0.3)
    output_file = get_output_path('scaling_comparison.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_zero_weight_comparison():
    if not check_file('zero_weight_comparison.csv'): return
    print("Plotting Zero Weight Fallback Comparison...")
    df = pd.read_csv(get_input_path('zero_weight_comparison.csv'))
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(df['x'], df['y_noisy'], 'o', markersize=4, alpha=0.4, color='gray', label='Data with Extreme Outlier')
    ax.plot(df['x'], df['y_mean'], '-', lw=2.5, label='UseLocalMean Fallback', color='#3b82f6')
    ax.plot(df['x'], df['y_original'], '--', lw=2.5, label='ReturnOriginal Fallback', color='#ef4444')
    ax.set_title('Zero-Weight Fallback Policies', fontsize=14, fontweight='bold')
    # Use index 50 for annotation
    ann_x = df.iloc[50]['x']
    ann_y = df.iloc[50]['y_noisy']
    ax.annotate('Extreme Outlier (Zero-Weighted)', 
                 xy=(ann_x, ann_y), xytext=(ann_x + 1, ann_y - 20),
                 arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=5))
    ax.set_ylim(-2, 110)
    ax.legend()
    ax.grid(True, alpha=0.3)
    output_file = get_output_path('zero_weight_comparison.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_degree_interpolation_comparison():
    if not check_file('degree_interpolation_comparison.csv'): return
    print("Plotting Degree Interpolation Comparison...")
    df = pd.read_csv(get_input_path('degree_interpolation_comparison.csv'))
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    axes = axes.flatten()

    configs = [
        ('Linear', 'y_lin_direct', 'y_lin_interp', '#3b82f6', '#93c5fd'),
        ('Quadratic', 'y_quad_direct', 'y_quad_interp', '#ef4444', '#fca5a5'),
        ('Cubic', 'y_cubic_direct', 'y_cubic_interp', '#8b5cf6', '#c4b5fd'),
        ('Quartic', 'y_quartic_direct', 'y_quartic_interp', '#10b981', '#6ee7b7'),
    ]

    for i, (name, d_col, i_col, d_color, i_color) in enumerate(configs):
        ax = axes[i]
        ax.plot(df['x'], df['y_noisy'], 'o', markersize=3, alpha=0.3, color='gray')
        ax.plot(df['x'], df['y_true'], 'k--', lw=1, alpha=0.5)
        ax.plot(df['x'], df[d_col], '-', lw=2.5, label=f'{name} Direct', color=d_color)
        ax.plot(df['x'], df[i_col], '--', lw=2.5, label=f'{name} Interp', color=i_color)
        ax.set_title(f'{name} Degree', fontsize=12, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)

    fig.suptitle('Surface Evaluation Fidelity across polynomial Degrees: Direct vs Interpolation', fontsize=16, fontweight='bold')
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    output_file = get_output_path('degree_interpolation_comparison.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_streaming_comparison():
    if not check_file('streaming_comparison.csv'): return
    print("Plotting Streaming Comparison...")
    df = pd.read_csv(get_input_path('streaming_comparison.csv'))
    fig, ax = plt.subplots(figsize=(12, 7))

    ax.plot(df['x'], df['y_noisy'], 'o', markersize=3, alpha=0.2, color='gray', label='Noisy Data')
    ax.plot(df['x'], df['y_true'], 'k--', lw=1.5, label='True Signal', alpha=0.6)
    
    ax.plot(df['x'], df['y_weighted'], '-', lw=3, label='Streaming (WeightedAverage)', color='#3b82f6')
    ax.plot(df['x'], df['y_average'], '--', lw=2, label='Streaming (Average)', color='#ef4444')
    ax.plot(df['x'], df['y_first'], ':', lw=2, label='Streaming (TakeFirst)', color='#10b981')

    ax.set_title('Streaming fastLowess: Comparison of Merge Strategies', fontsize=14, fontweight='bold')
    ax.set_xlabel('Time (x)')
    ax.set_ylabel('Value (y)')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    output_file = get_output_path('streaming_comparison.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_online_comparison():
    if not check_file('online_comparison.csv'): return
    print("Plotting Online Comparison...")
    df = pd.read_csv(get_input_path('online_comparison.csv'))
    fig, ax = plt.subplots(figsize=(12, 7))

    ax.plot(df['x'], df['y_noisy'], 'o', markersize=3, alpha=0.3, color='gray', label='Streaming Data')
    ax.plot(df['x'], df['y_true'], 'k--', lw=1.5, label='True Signal', alpha=0.6)
    
    ax.plot(df['x'], df['y_small_window'], '-', lw=2.5, label='Online (Window=50, Incremental)', color='#ef4444')
    ax.plot(df['x'], df['y_large_window'], '-', lw=3, label='Online (Window=200, Full + Robust)', color='#3b82f6')

    ax.set_title('Online fastLowess: Incremental Smoothing with Sliding Window', fontsize=14, fontweight='bold')
    ax.set_xlabel('Point Index')
    ax.set_ylabel('Value')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # Highlight the shift
    ax.axvline(250, color='gray', linestyle=':', alpha=0.5)
    ax.text(255, ax.get_ylim()[1]*0.9, 'Signal Shift', color='gray', fontsize=10)

    output_file = get_output_path('online_comparison.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

def plot_auto_converge_comparison():
    if not check_file('auto_converge_comparison.csv'): return
    print("Plotting Auto-Convergence Comparison...")
    df = pd.read_csv(get_input_path('auto_converge_comparison.csv'))
    
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))
    
    adapters = [
        ('Batch', 'batch', ax1, '#3b82f6'),
        ('Streaming', 'stream', ax2, '#10b981'),
        ('Online', 'online', ax3, '#ef4444')
    ]
    
    for name, key, ax, base_color in adapters:
        # Plot context
        ax.plot(df['x'], df['y_noisy'], 'o', markersize=2, alpha=0.15, color='gray', label='Noisy Data')
        ax.plot(df['x'], df['y_true'], 'k--', lw=1, label='True Signal', alpha=0.4)
        
        # Plot Off/On fits
        # Off: Dashed, darker/distinct
        ax.plot(df['x'], df[f'y_{key}_off'], '--', lw=3, label=f'{name} (Standard)', color='gray')
        # On: Solid, colored
        ax.plot(df['x'], df[f'y_{key}_on'], '-', lw=2, label=f'{name} (Auto-Converge)', color=base_color)
        
        # Calculate max iterations saved for title/annotation
        saved = (df[f'iter_{key}_off'] - df[f'iter_{key}_on'])
        avg_saved = saved.mean()
        total_saved = saved.sum()
        
        ax.set_title(f'{name} Adapter\nSaved: {total_saved:.0f} iters (Avg {avg_saved:.1f}/pt)', fontsize=12, fontweight='bold')
        ax.legend(loc='upper right', fontsize=9)
        ax.grid(True, alpha=0.3)
        ax.set_xlabel('X')
        if ax == ax1:
            ax.set_ylabel('Y')

    plt.tight_layout()
    output_file = get_output_path('auto_converge_comparison.svg')
    plt.savefig(output_file, format='svg', bbox_inches='tight', dpi=72)
    print(f'Saved to {output_file}')
    plt.close()

if __name__ == "__main__":
    
    # Ensure output directory exists for figures
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    if len(sys.argv) < 2:
        target = 'all'
    else:
        target = sys.argv[1]

    if target == 'all':
        plot_degree_comparison()
        plot_fraction_comparison()
        plot_intervals_comparison()
        plot_robustness_comparison()
        plot_fastLowess_concept()
        plot_multivariate_fastLowess()
        plot_kernel_comparison()
        plot_robust_method_comparison()
        plot_boundary_policy_comparison()
        plot_higher_degree_comparison()
        plot_gap_handling()
        plot_cv_comparison()
        plot_surface_mode_comparison()
        plot_scaling_comparison()
        plot_zero_weight_comparison()
        plot_degree_interpolation_comparison()
        plot_streaming_comparison()
        plot_online_comparison()
        plot_auto_converge_comparison()
    elif target == 'degree':
        plot_degree_comparison()
    elif target == 'fraction':
        plot_fraction_comparison()
    elif target == 'intervals':
        plot_intervals_comparison()
    elif target == 'robustness':
        plot_robustness_comparison()
    elif target == 'concept':
        plot_fastLowess_concept()
    elif target == 'multivariate':
        plot_multivariate_fastLowess()
    elif target == 'kernel':
        plot_kernel_comparison()
    elif target == 'robust_method':
        plot_robust_method_comparison()
    elif target == 'boundary':
        plot_boundary_policy_comparison()
    elif target == 'higher_degree':
        plot_higher_degree_comparison()
    elif target == 'gap':
        plot_gap_handling()
    elif target == 'cv':
        plot_cv_comparison()
    elif target == 'surface':
        plot_surface_mode_comparison()
    elif target == 'scaling':
        plot_scaling_comparison()
    elif target == 'zero_weight':
        plot_zero_weight_comparison()
    elif target == 'degree_interp':
        plot_degree_interpolation_comparison()
    elif target == 'streaming':
        plot_streaming_comparison()
    elif target == 'online':
        plot_online_comparison()
    elif target == 'auto_converge':
        plot_auto_converge_comparison()
    else:
        print(f"Unknown target: {target}")
        print("Usage: python3 plot.py [target] (default: all)")
        print("Targets: all, degree, fraction, intervals, robustness, concept, multivariate, kernel, robust_method, boundary, higher_degree, gap, cv, surface, scaling, zero_weight, degree_interp, streaming, online, auto_converge")
